const express = require('express');
const router = express.Router();
const { 
  getNetworkStats, 
  getBlockchainInfo, 
  getBestBlockHash, 
  getBlock, 
  executeRpcCommand,
  getRawTransaction
} = require('../services/bitcoinzService');
const logger = require('../utils/logger');

// Mining pool extraction and mapping
const getPoolName = (coinbaseData) => {
  try {
    const coinbaseString = coinbaseData.toString();
    
    // These patterns match common signatures in coinbase data
    const poolPatterns = [
      { pattern: /zpool.ca/, name: 'Zpool' },
      { pattern: /zergpool/, name: 'Zergpool' },
      { pattern: /darkfibermines/i, name: 'DarkFiberMines' },
      { pattern: /2miners|2mars/i, name: '2Mars' },
      { pattern: /solopool/i, name: 'Solo Pool' },
      { pattern: /f2pool/i, name: 'F2Pool' },
      { pattern: /viabtc/i, name: 'ViaBTC' },
      { pattern: /btcz.pool/i, name: 'BTCZ Pool' },
    ];
    
    for (const pool of poolPatterns) {
      if (pool.pattern.test(coinbaseString)) {
        return pool.name;
      }
    }
  } catch (err) {
    logger.warn('Error extracting pool name from coinbase data:', err);
  }
  
  return 'Unknown';
};

// Get mining pool distribution data from recent blocks
const getMiningPoolsData = async (blocksCount = 100) => {
  try {
    // 1. Get the latest block height
    const bestBlockHash = await getBestBlockHash();
    if (!bestBlockHash) {
      throw new Error('Failed to get best block hash');
    }
    
    const bestBlock = await getBlock(bestBlockHash);
    if (!bestBlock || typeof bestBlock.height !== 'number') {
      throw new Error('Failed to get best block info');
    }
    
    const height = bestBlock.height;
    logger.info(`Getting mining pool data from ${blocksCount} blocks starting from height ${height}`);
    
    // 2. Get recent blocks
    const poolCounts = {};
    let totalBlocks = 0;
    
    // Process fewer blocks if we encounter too many errors
    let errorCount = 0;
    const MAX_ERRORS = 10;
    
    for (let i = 0; i < blocksCount && i < height && errorCount < MAX_ERRORS; i++) {
      try {
        const blockHash = await executeRpcCommand('getblockhash', [height - i]);
        if (!blockHash) {
          logger.warn(`No block hash found for height ${height - i}`);
          continue;
        }
        
        const block = await getBlock(blockHash, true);
        if (!block || !block.tx || !Array.isArray(block.tx) || !block.tx.length) {
          logger.warn(`Invalid block data for hash ${blockHash}`);
          continue;
        }
        
        // Get the coinbase transaction (first transaction in block)
        const coinbaseTx = await getRawTransaction(block.tx[0], 1);
        if (!coinbaseTx || !coinbaseTx.vin || !coinbaseTx.vin[0]) {
          logger.warn(`Invalid coinbase transaction for block ${blockHash}`);
          continue;
        }
        
        // Extract pool name from coinbase data (if available)
        let poolName = 'Unknown';
        if (coinbaseTx.vin[0].coinbase) {
          try {
            const coinbaseData = Buffer.from(coinbaseTx.vin[0].coinbase, 'hex');
            poolName = getPoolName(coinbaseData);
          } catch (err) {
            logger.warn(`Error parsing coinbase data: ${err.message}`);
          }
        }
        
        // Increment counter for this pool
        poolCounts[poolName] = (poolCounts[poolName] || 0) + 1;
        totalBlocks++;
      } catch (err) {
        errorCount++;
        logger.error(`Error processing block at height ${height - i}: ${err.message}`);
        // Continue with next block
      }
    }
    
    if (totalBlocks === 0) {
      throw new Error('No valid blocks found to analyze');
    }
    
    // 3. Calculate percentages
    const poolData = Object.keys(poolCounts).map(name => {
      const count = poolCounts[name];
      return {
        name,
        count,
        percentage: parseFloat(((count / totalBlocks) * 100).toFixed(1))
      };
    });
    
    // Sort by percentage (highest first)
    poolData.sort((a, b) => b.percentage - a.percentage);
    
    // Group smaller miners if there are too many
    if (poolData.length > 5) {
      const mainPools = poolData.slice(0, 4);
      const otherPools = poolData.slice(4);
      
      const otherCount = otherPools.reduce((sum, pool) => sum + pool.count, 0);
      const otherPercentage = otherPools.reduce((sum, pool) => sum + pool.percentage, 0);
      
      mainPools.push({
        name: 'Others',
        count: otherCount,
        percentage: parseFloat(otherPercentage.toFixed(1))
      });
      
      return mainPools;
    }
    
    return poolData;
  } catch (error) {
    logger.error('Error getting mining pool data:', error);
    // Fallback to default data if there's an error
    return [
      { name: 'Zpool', percentage: 31.8 },
      { name: 'Zergpool', percentage: 49.0 },
      { name: 'Others', count: 33, percentage: 11.1 },
      { name: 'DarkFiberMines', percentage: 6.1 },
      { name: '2Mars', percentage: 2.0 }
    ];
  }
};

// Get block size chart data
router.get('/block-size', async (req, res, next) => {
  try {
    logger.info('Fetching block size chart data');

    // In a production environment, this would fetch real data from the database
    // For now, we'll generate mock data
    const days = parseInt(req.query.days) || 30;
    const date = req.query.date || new Date().toISOString().split('T')[0];
    
    // Generate random block size data
    const chartData = Array(days).fill(0).map((_, i) => {
      // Block height decreases as we go back in time
      const blockHeight = 1545720 - i * 10;
      
      // Random block size between 500 and 10000 bytes
      // Occasionally generate higher values for visual interest
      let blockSize = Math.floor(Math.random() * 3000) + 500;
      if (Math.random() < 0.1) {
        blockSize = Math.floor(Math.random() * 10000) + 5000;
      }
      
      return {
        blockHeight,
        blockSize,
        timestamp: new Date(Date.now() - (i * 86400000)).toISOString()
      };
    }).reverse(); // Oldest first
    
    res.json({
      date,
      days,
      chartType: 'block-size',
      data: chartData
    });
  } catch (error) {
    logger.error('Error fetching block size chart data:', error);
    next(error);
  }
});

// Get block interval chart data
router.get('/block-interval', async (req, res, next) => {
  try {
    logger.info('Fetching block interval chart data');
    
    const days = parseInt(req.query.days) || 30;
    const date = req.query.date || new Date().toISOString().split('T')[0];
    
    // Generate random block interval data (in seconds)
    const chartData = Array(days).fill(0).map((_, i) => {
      const blockHeight = 1545720 - i * 10;
      
      // Random interval between 60 and 900 seconds (1-15 minutes)
      const interval = Math.floor(Math.random() * 840) + 60;
      
      return {
        blockHeight,
        interval,
        timestamp: new Date(Date.now() - (i * 86400000)).toISOString()
      };
    }).reverse();
    
    res.json({
      date,
      days,
      chartType: 'block-interval',
      data: chartData
    });
  } catch (error) {
    logger.error('Error fetching block interval chart data:', error);
    next(error);
  }
});

// Get difficulty chart data
router.get('/difficulty', async (req, res, next) => {
  try {
    logger.info('Fetching difficulty chart data');
    
    const days = parseInt(req.query.days) || 30;
    const date = req.query.date || new Date().toISOString().split('T')[0];
    
    // Generate random difficulty data
    const chartData = Array(days).fill(0).map((_, i) => {
      const blockHeight = 1545720 - i * 10;
      
      // Somewhat realistic difficulty pattern with gradual increases
      const baseDifficulty = 700;
      const trend = i * 0.5; // Gradual increase going back in time
      const random = Math.random() * 20 - 10; // Random fluctuation
      const difficulty = baseDifficulty - trend + random;
      
      return {
        blockHeight,
        difficulty: parseFloat(difficulty.toFixed(2)),
        timestamp: new Date(Date.now() - (i * 86400000)).toISOString()
      };
    }).reverse();
    
    res.json({
      date,
      days,
      chartType: 'difficulty',
      data: chartData
    });
  } catch (error) {
    logger.error('Error fetching difficulty chart data:', error);
    next(error);
  }
});

// Get mining revenue chart data
router.get('/mining-revenue', async (req, res, next) => {
  try {
    logger.info('Fetching mining revenue chart data');
    
    const days = parseInt(req.query.days) || 30;
    const date = req.query.date || new Date().toISOString().split('T')[0];
    
    // Generate random mining revenue data in BTCZ
    const chartData = Array(days).fill(0).map((_, i) => {
      const blockHeight = 1545720 - i * 10;
      
      // Random revenue between 5 and 15 BTCZ per block
      const revenue = 5 + Math.random() * 10;
      
      return {
        blockHeight,
        revenue: parseFloat(revenue.toFixed(4)),
        timestamp: new Date(Date.now() - (i * 86400000)).toISOString()
      };
    }).reverse();
    
    res.json({
      date,
      days,
      chartType: 'mining-revenue',
      data: chartData
    });
  } catch (error) {
    logger.error('Error fetching mining revenue chart data:', error);
    next(error);
  }
});

// Get pool distribution data
router.get('/pool-stat', async (req, res, next) => {
  try {
    logger.info('Fetching pool distribution data');
    
    const date = req.query.date || new Date().toISOString().split('T')[0];
    const blocksToAnalyze = parseInt(req.query.blocks) || 100;
    
    // Get dynamic mining pool data
    const poolData = await getMiningPoolsData(blocksToAnalyze);
    
    res.json({
      date,
      chartType: 'pool-stat',
      data: poolData
    });
  } catch (error) {
    logger.error('Error fetching pool distribution data:', error);
    next(error);
  }
});

// Get mined blocks by pool
router.get('/mined-block', async (req, res, next) => {
  try {
    logger.info('Fetching mined blocks data');
    
    const days = parseInt(req.query.days) || 30;
    const date = req.query.date || new Date().toISOString().split('T')[0];
    
    // Use default pool distribution in case of error with dynamic data
    let poolDistribution = [
      { name: 'Zpool', percentage: 31.8 },
      { name: 'Zergpool', percentage: 49.0 },
      { name: 'Others', percentage: 11.1 },
      { name: 'DarkFiberMines', percentage: 6.1 },
      { name: '2Mars', percentage: 2.0 }
    ];
    
    // Try to get dynamic pool data, but fallback to defaults if it fails
    try {
      const dynamicPools = await getMiningPoolsData(100);
      if (dynamicPools && dynamicPools.length > 0) {
        poolDistribution = dynamicPools;
      }
    } catch (poolError) {
      logger.error('Error fetching pool distribution, using default values:', poolError);
    }
    
    // Generate random mined blocks data
    const chartData = Array(days * 10).fill(0).map((_, i) => {
      const blockHeight = 1545720 - i;
      
      // Assign a pool based on the pool distribution
      let pool = 'Unknown';
      const rand = Math.random() * 100;
      
      // Simple implementation to assign blocks to pools based on their percentage
      let cumulativePercentage = 0;
      for (const poolInfo of poolDistribution) {
        cumulativePercentage += poolInfo.percentage;
        if (rand < cumulativePercentage) {
          pool = poolInfo.name;
          break;
        }
      }
      
      // Random block size
      const size = Math.floor(Math.random() * 3000) + 500;
      
      return {
        blockHeight,
        pool,
        size,
        timestamp: new Date(Date.now() - (i * 8640000)).toISOString()
      };
    }).reverse();
    
    res.json({
      date,
      days,
      chartType: 'mined-block',
      data: chartData
    });
  } catch (error) {
    logger.error('Error fetching mined blocks data:', error);
    next(error);
  }
});

module.exports = router;